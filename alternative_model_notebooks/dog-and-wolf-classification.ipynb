{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":9024381,"sourceType":"datasetVersion","datasetId":5438619},{"sourceId":9031137,"sourceType":"datasetVersion","datasetId":5443361},{"sourceId":9038410,"sourceType":"datasetVersion","datasetId":5448630},{"sourceId":9039833,"sourceType":"datasetVersion","datasetId":5427694},{"sourceId":9040266,"sourceType":"datasetVersion","datasetId":5432323},{"sourceId":81368,"sourceType":"modelInstanceVersion","modelInstanceId":68377,"modelId":93559},{"sourceId":82748,"sourceType":"modelInstanceVersion","modelInstanceId":69510,"modelId":94648}],"dockerImageVersionId":30746,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport sys\nimport copy\nimport librosa\nimport torch\nimport random\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom pathlib import Path\nfrom tqdm.notebook import tqdm\nfrom IPython.display import Audio, FileLink\nfrom torch.utils.data import Dataset, DataLoader\nfrom torchvision import transforms\nfrom torchvision.models import resnet18\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import classification_report\nfrom sklearn.metrics import precision_score, recall_score, f1_score\nfrom sklearn.metrics import confusion_matrix","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-08-01T05:15:03.760686Z","iopub.execute_input":"2024-08-01T05:15:03.761496Z","iopub.status.idle":"2024-08-01T05:15:03.767786Z","shell.execute_reply.started":"2024-08-01T05:15:03.761464Z","shell.execute_reply":"2024-08-01T05:15:03.766962Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Cчитывание данные","metadata":{}},{"cell_type":"code","source":"data = []\nfor path in Path(\"/kaggle/input/dog-wolf-nature/dog_wolf_nature/not_dog\").glob(\"*.wav\"):\n    try:\n        data.append({\"path\": path, \"label\": 0})\n    except Exception as e:\n        print(e)","metadata":{"execution":{"iopub.status.busy":"2024-08-01T05:13:34.932076Z","iopub.execute_input":"2024-08-01T05:13:34.932583Z","iopub.status.idle":"2024-08-01T05:13:35.231511Z","shell.execute_reply.started":"2024-08-01T05:13:34.932554Z","shell.execute_reply":"2024-08-01T05:13:35.230354Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for path in Path(\"/kaggle/input/dog-wolf-nature/dog_wolf_nature/dog\").glob(\"*.wav\"):\n    try:\n        data.append({\"path\": path, \"label\": 1})\n    except Exception as e:\n        print(e)","metadata":{"execution":{"iopub.status.busy":"2024-08-01T05:13:36.517807Z","iopub.execute_input":"2024-08-01T05:13:36.518170Z","iopub.status.idle":"2024-08-01T05:13:36.632290Z","shell.execute_reply.started":"2024-08-01T05:13:36.518142Z","shell.execute_reply":"2024-08-01T05:13:36.631343Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for path in Path(\"/kaggle/input/dog-wolf-nature/dog_wolf_nature/wolf\").glob(\"*.wav\"):\n    try:\n        data.append({\"path\": path, \"label\": 2})\n    except Exception as e:\n        print(e)","metadata":{"execution":{"iopub.status.busy":"2024-08-01T05:13:38.654690Z","iopub.execute_input":"2024-08-01T05:13:38.655055Z","iopub.status.idle":"2024-08-01T05:13:38.751840Z","shell.execute_reply.started":"2024-08-01T05:13:38.655027Z","shell.execute_reply":"2024-08-01T05:13:38.750969Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data = pd.DataFrame(data)\ndata.head(5)","metadata":{"execution":{"iopub.status.busy":"2024-08-01T05:13:40.432139Z","iopub.execute_input":"2024-08-01T05:13:40.433031Z","iopub.status.idle":"2024-08-01T05:13:40.454892Z","shell.execute_reply.started":"2024-08-01T05:13:40.432993Z","shell.execute_reply":"2024-08-01T05:13:40.453999Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"target_rate = 16_000                                        # частота дискретизации аудио\ntarget_length = target_rate * 10                            # длина аудио\nnum_classes = 3                                             # количесвто классов для предсказания\ndevice = ('cuda:0' if torch.cuda.is_available() else 'cpu') # устройство","metadata":{"execution":{"iopub.status.busy":"2024-08-01T05:13:43.167767Z","iopub.execute_input":"2024-08-01T05:13:43.168565Z","iopub.status.idle":"2024-08-01T05:13:43.206353Z","shell.execute_reply.started":"2024-08-01T05:13:43.168528Z","shell.execute_reply":"2024-08-01T05:13:43.205341Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# выделение тестового набора данных (по необходимости)\ndata, val = train_test_split(data, test_size=0.5, random_state=42, stratify=data[\"label\"])\ndata = data.reset_index(drop=True)\ndata.head(5)","metadata":{"execution":{"iopub.status.busy":"2024-08-01T05:13:46.006490Z","iopub.execute_input":"2024-08-01T05:13:46.006841Z","iopub.status.idle":"2024-08-01T05:13:46.025636Z","shell.execute_reply.started":"2024-08-01T05:13:46.006812Z","shell.execute_reply":"2024-08-01T05:13:46.024807Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# разбиение датасета на train и test\ntrain, test = train_test_split(data, test_size=0.2, random_state=42, stratify=data[\"label\"])\ntrain = train.reset_index(drop=True)\ntest = test.reset_index(drop=True)\ntrain.head(5)","metadata":{"execution":{"iopub.status.busy":"2024-08-01T05:13:48.606354Z","iopub.execute_input":"2024-08-01T05:13:48.607264Z","iopub.status.idle":"2024-08-01T05:13:48.620281Z","shell.execute_reply.started":"2024-08-01T05:13:48.607227Z","shell.execute_reply":"2024-08-01T05:13:48.619316Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Предобработка данных","metadata":{}},{"cell_type":"code","source":"# определение класса для применения аугментаций\nclass ComposeTransforms:\n    def __init__(self, transforms_probs):\n        self.transforms_probs = transforms_probs\n    def __call__(self, waveform):\n        for transform, prob in self.transforms_probs:\n            if random.random() < prob:\n                waveform = transform(waveform)\n        return waveform","metadata":{"execution":{"iopub.status.busy":"2024-08-01T05:13:51.421941Z","iopub.execute_input":"2024-08-01T05:13:51.422297Z","iopub.status.idle":"2024-08-01T05:13:51.428277Z","shell.execute_reply.started":"2024-08-01T05:13:51.422271Z","shell.execute_reply":"2024-08-01T05:13:51.427258Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# аугментация изменения скорости\ndef change_speed(waveform, length=160_000):\n    speed = random.choice([0.8, 0.9, 1.1, 1.2])\n    result = librosa.effects.time_stretch(waveform, rate=speed)\n    if len(result) > length:\n        result = result[:length]\n    else:\n        begin = (length - len(result)) // 2\n        end = (length - len(result)) - begin\n        result = np.pad(result, (begin, end), \"constant\")\n    return result","metadata":{"execution":{"iopub.status.busy":"2024-08-01T05:13:53.356524Z","iopub.execute_input":"2024-08-01T05:13:53.356863Z","iopub.status.idle":"2024-08-01T05:13:53.363186Z","shell.execute_reply.started":"2024-08-01T05:13:53.356835Z","shell.execute_reply":"2024-08-01T05:13:53.362096Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# аугментация изменения тона\ndef change_pitch(waveform, sample_rate=16_000):\n    n_steps = random.choice([-1.75, -1.5, -1.25, -1, 1, 1.25, 1.5, 1.75])\n    return librosa.effects.pitch_shift(waveform, sr=sample_rate, n_steps=n_steps)","metadata":{"execution":{"iopub.status.busy":"2024-08-01T05:13:55.136214Z","iopub.execute_input":"2024-08-01T05:13:55.136601Z","iopub.status.idle":"2024-08-01T05:13:55.142050Z","shell.execute_reply.started":"2024-08-01T05:13:55.136568Z","shell.execute_reply":"2024-08-01T05:13:55.140979Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# аугментация сдвига по времени\ndef time_shift(waveform):\n    return np.roll(waveform, random.randint(40_000, 60_000))","metadata":{"execution":{"iopub.status.busy":"2024-08-01T05:13:57.004959Z","iopub.execute_input":"2024-08-01T05:13:57.005303Z","iopub.status.idle":"2024-08-01T05:13:57.010039Z","shell.execute_reply.started":"2024-08-01T05:13:57.005275Z","shell.execute_reply":"2024-08-01T05:13:57.009029Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# объект для применения аугментаций к аудио\ntransform_audio = ComposeTransforms([\n    (change_pitch, 0.25),\n    (change_speed, 0.25),\n    (time_shift, 0.25)\n])","metadata":{"execution":{"iopub.status.busy":"2024-08-01T05:13:58.695623Z","iopub.execute_input":"2024-08-01T05:13:58.696199Z","iopub.status.idle":"2024-08-01T05:13:58.700843Z","shell.execute_reply.started":"2024-08-01T05:13:58.696167Z","shell.execute_reply":"2024-08-01T05:13:58.699725Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# аугментнация маскирования спектрограммы аудио\ndef frequency_mask(mel_sgram, max_width=15):\n    aug_sgram = copy.deepcopy(mel_sgram)\n    num_mask = random.choice([0, 1, 2])\n    for i in range(num_mask):\n        width = random.randint(0, max_width)\n        start = random.randint(0, aug_sgram.shape[0] - width)\n        aug_sgram[start:start+width, :] = 0\n    return aug_sgram","metadata":{"execution":{"iopub.status.busy":"2024-08-01T05:14:00.357397Z","iopub.execute_input":"2024-08-01T05:14:00.357754Z","iopub.status.idle":"2024-08-01T05:14:00.364486Z","shell.execute_reply.started":"2024-08-01T05:14:00.357724Z","shell.execute_reply":"2024-08-01T05:14:00.363340Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# аугментнация маскирования спектрограммы аудио\ndef time_mask(mel_sgram, max_width=20):\n    aug_sgram = copy.deepcopy(mel_sgram)\n    num_mask = random.choice([0, 1, 2])\n    for i in range(num_mask):\n        width = random.randint(0, max_width)\n        start = random.randint(0, aug_sgram.shape[1] - width)\n        aug_sgram[:, start:start+width] = 0\n    return aug_sgram","metadata":{"execution":{"iopub.status.busy":"2024-08-01T05:14:02.085106Z","iopub.execute_input":"2024-08-01T05:14:02.085428Z","iopub.status.idle":"2024-08-01T05:14:02.091426Z","shell.execute_reply.started":"2024-08-01T05:14:02.085403Z","shell.execute_reply":"2024-08-01T05:14:02.090313Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# объект для примнения аугментаций к спектрограмме аудио\ntransform_sgram = ComposeTransforms([\n    (frequency_mask, 0.25),\n    (time_mask, 0.25)\n])","metadata":{"execution":{"iopub.status.busy":"2024-08-01T05:14:04.141774Z","iopub.execute_input":"2024-08-01T05:14:04.142132Z","iopub.status.idle":"2024-08-01T05:14:04.146837Z","shell.execute_reply.started":"2024-08-01T05:14:04.142103Z","shell.execute_reply":"2024-08-01T05:14:04.145836Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# определение класса кастомного датасета\nclass CustomAudioDataset(Dataset):\n    def __init__(self, paths, labels, target_rate, target_length, transform_audio=None, transform_sgram=None, overlay=False):\n        self.paths = paths\n        self.labels = labels\n        self.target_rate = target_rate\n        self.target_length = target_length\n        self.transform_audio = transform_audio\n        self.transform_sgram = transform_sgram\n        self.overlay = overlay\n    def __len__(self):\n        return len(self.labels)\n    def __getitem__(self, idx):\n        waveform, sr = librosa.load(self.paths[idx])\n        label = self.labels[idx]\n        waveform = self.preprocess_wave(waveform, sr)\n        if self.overlay:\n            if (label == 2) or (label == 1):\n                mask = np.array(self.labels) == 0\n                filtered_paths = np.array(self.paths)[mask]\n                random_path = random.choice(filtered_paths)\n                zero_label_wave, zero_label_sr = librosa.load(random_path)\n                zero_label_wave = self.preprocess_wave(zero_label_wave, zero_label_sr)\n                waveform = self.overlay_audio(waveform, zero_label_wave)\n        if self.transform_audio:\n            waveform = self.transform_audio(waveform)\n        mel_sgram = self.get_spectrogram(waveform, sr)\n        if self.transform_sgram:\n            mel_sgram = self.transform_sgram(mel_sgram)\n        mel_sgram = self.standardization(mel_sgram)\n        mel_sgram = self.to_tensor(mel_sgram)\n        return mel_sgram, label\n    # rms номрализация аудио\n    def rms_audio_normalization(self, wave, target_dBFS=-20):\n        rms = np.sqrt(np.mean(wave ** 2))\n        target_rms = 10 ** (rms / 20)\n        if rms == 0:\n            return wave\n        gain = target_rms / rms\n        wave_norm = wave * gain\n        return wave_norm\n    # аугментация наложения аудио 0 класса на аудио 1 и 2 классов\n    def overlay_audio(self, positive, negative):\n        min_len = min(len(positive), len(negative))\n        positive = positive[:min_len]\n        negative = negative[:min_len]\n        result = positive + negative\n        return result\n    # стандартизация спектрограммы по временым промежуткам\n    def standardization(self, mel_sgram):\n        mel_sgram = mel_sgram.T\n        mel_sgram_stand = np.zeros_like(mel_sgram)\n        for i in range(mel_sgram.shape[0]):\n            mean = np.mean(mel_sgram[i])\n            std = np.std(mel_sgram[i])\n            if std != 0:\n                mel_sgram_stand[i] = (mel_sgram[i] - mean) / std\n            else:\n                mel_sgram_stand[i] = mel_sgram[i] - mean\n        mel_sgram_stand = mel_sgram_stand.T\n        return mel_sgram_stand\n    def to_tensor(self, mel_sgram):\n        tensor = torch.tensor(mel_sgram)\n        tensor = tensor.unsqueeze(0)\n        return tensor.float()\n    # изменение длины, частоты дискретизации аудио и перевод аудио в моно\n    def preprocess_wave(self, waveform, sr):\n        waveform = librosa.resample(waveform, orig_sr=sr, target_sr=self.target_rate)        \n        waveform = librosa.to_mono(waveform)        \n        if len(waveform) > self.target_length:\n            waveform = waveform[:self.target_length]\n        elif len(waveform) < self.target_length:\n            pad_length = self.target_length - len(waveform)\n            zeros = np.zeros(pad_length)\n            waveform = np.concatenate((waveform, zeros))\n        waveform = self.rms_audio_normalization(waveform)\n        return waveform\n    # получение спектрограммы аудио\n    def get_spectrogram(self, waveform, sr):\n        sgram = librosa.stft(waveform)\n        magnitude = librosa.magphase(sgram)[0]\n        mel_sgram = librosa.feature.melspectrogram(S=magnitude, sr=sr)\n        mel_sgram_db = librosa.amplitude_to_db(mel_sgram, ref=np.min)\n        return mel_sgram_db","metadata":{"execution":{"iopub.status.busy":"2024-08-01T05:14:07.027033Z","iopub.execute_input":"2024-08-01T05:14:07.027403Z","iopub.status.idle":"2024-08-01T05:14:07.046860Z","shell.execute_reply.started":"2024-08-01T05:14:07.027372Z","shell.execute_reply":"2024-08-01T05:14:07.045990Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"learning_rate = 0.00001\nbatch_size = 16","metadata":{"execution":{"iopub.status.busy":"2024-08-01T05:14:10.872778Z","iopub.execute_input":"2024-08-01T05:14:10.873658Z","iopub.status.idle":"2024-08-01T05:14:10.877783Z","shell.execute_reply.started":"2024-08-01T05:14:10.873624Z","shell.execute_reply":"2024-08-01T05:14:10.876583Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# инстансы кастомных датасетов для train и test\ntrain_audio_dataset = CustomAudioDataset(train[\"path\"].tolist(), train[\"label\"].tolist(), target_rate, target_length, transform_audio=transform_audio, transform_sgram=transform_sgram, overlay=True)\ntest_audio_dataset = CustomAudioDataset(test[\"path\"].tolist(), test[\"label\"].tolist(), target_rate, target_length, overlay=True)\ntrain_dataloader = DataLoader(train_audio_dataset, batch_size=batch_size, shuffle=True)\ntest_dataloader = DataLoader(test_audio_dataset, batch_size=batch_size, shuffle=False)","metadata":{"execution":{"iopub.status.busy":"2024-08-01T05:14:12.630113Z","iopub.execute_input":"2024-08-01T05:14:12.630448Z","iopub.status.idle":"2024-08-01T05:14:12.637200Z","shell.execute_reply.started":"2024-08-01T05:14:12.630422Z","shell.execute_reply":"2024-08-01T05:14:12.636131Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Обучение модели","metadata":{}},{"cell_type":"code","source":"# определение класса для измененного ResNet18 для нашей задачи\nclass CustomResNet(torch.nn.Module):    \n    def __init__(self, num_classes):\n        super().__init__()\n        self.resnet = resnet18(weights=None)\n        self.resnet.conv1 = torch.nn.Conv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)     \n        in_features = self.resnet.fc.in_features\n        self.resnet.fc = torch.nn.Linear(in_features, num_classes)   \n    def forward(self, x):\n        return self.resnet(x)","metadata":{"execution":{"iopub.status.busy":"2024-08-01T05:14:19.289218Z","iopub.execute_input":"2024-08-01T05:14:19.289560Z","iopub.status.idle":"2024-08-01T05:14:19.296043Z","shell.execute_reply.started":"2024-08-01T05:14:19.289532Z","shell.execute_reply":"2024-08-01T05:14:19.295090Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"custom_model = CustomResNet(num_classes)\ncustom_model = custom_model.to(device)\nweights = torch.tensor([1.0, 1.0, 1.0]).to(device)\nloss_function = torch.nn.CrossEntropyLoss(weight=weights)\noptimizer = torch.optim.Adam(custom_model.parameters(), lr=learning_rate)","metadata":{"execution":{"iopub.status.busy":"2024-08-01T05:14:21.833000Z","iopub.execute_input":"2024-08-01T05:14:21.833331Z","iopub.status.idle":"2024-08-01T05:14:22.261073Z","shell.execute_reply.started":"2024-08-01T05:14:21.833305Z","shell.execute_reply":"2024-08-01T05:14:22.260054Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# цикл обучения\ndef train_epoch(model, loss_fn, optimizer, dataloader):\n    model.train()\n    sum_loss = 0\n    pbar = tqdm(dataloader, ascii=True, desc=\"Train\")\n    for i, (X, y) in enumerate(pbar):\n        X, y = X.to(device), y.to(device)\n        optimizer.zero_grad()\n        pred = model(X)\n        loss = loss_fn(pred, y)\n        sum_loss += loss.item()\n        loss.backward()\n        optimizer.step()\n    return sum_loss / len(dataloader)","metadata":{"execution":{"iopub.status.busy":"2024-08-01T05:14:24.423939Z","iopub.execute_input":"2024-08-01T05:14:24.424787Z","iopub.status.idle":"2024-08-01T05:14:24.432815Z","shell.execute_reply.started":"2024-08-01T05:14:24.424742Z","shell.execute_reply":"2024-08-01T05:14:24.431708Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# цикл оценки\ndef eval_epoch(model, loss_fn, dataloader):\n    model.eval()\n    sum_loss = 0\n    all_y_true = []\n    all_y_pred = []\n    pbar = tqdm(dataloader, ascii=True, desc=\"Validation\")\n    with torch.no_grad():\n        for i, (X, y) in enumerate(pbar):\n            X, y = X.to(device), y.to(device)\n            pred = model(X)\n            loss = loss_fn(pred, y)\n            sum_loss += loss.item()            \n            _, predicted_labels = torch.max(pred, 1)\n            all_y_true = all_y_true + y.tolist()\n            all_y_pred = all_y_pred + predicted_labels.tolist()\n    target_names = [\"Negative\", \"Dog\", \"Wolf\"]     \n    print(classification_report(all_y_true, all_y_pred, target_names=target_names))\n    avg_loss = sum_loss / len(dataloader)\n    return avg_loss","metadata":{"execution":{"iopub.status.busy":"2024-08-01T05:14:26.366233Z","iopub.execute_input":"2024-08-01T05:14:26.366593Z","iopub.status.idle":"2024-08-01T05:14:26.374376Z","shell.execute_reply.started":"2024-08-01T05:14:26.366564Z","shell.execute_reply":"2024-08-01T05:14:26.373408Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"loss_val_arr = []\nloss_train_arr = []\ncounter = 0  # счетчик для early stopping\npatience = 5 # уровень терпения для early stopping\nepochs = 15  # количество эпох для обучения\nbest_val_loss = sys.maxsize\nfor i in range(epochs):\n    print(f\"Epoch {i+1}\\n-------------------------------\")\n    train_loss = train_epoch(custom_model, loss_function, optimizer, train_dataloader)\n    val_loss = eval_epoch(custom_model, loss_function, test_dataloader)\n    loss_train_arr.append(train_loss)\n    loss_val_arr.append(val_loss)\n    print(f\"Train loss: {train_loss}\")\n    print(f\"Val loss: {val_loss}\")\n    if (val_loss < best_val_loss):\n        best_val_loss = val_loss\n        counter = 0\n        torch.save(custom_model.state_dict(), \"best_model\")\n    else:\n        counter += 1\n        if counter >= early_stop:\n            print(f\"Early stop on the epoch: {i + 1}, best validation loss: {best_val_loss}\")\n            break","metadata":{"execution":{"iopub.status.busy":"2024-08-01T05:15:12.135021Z","iopub.execute_input":"2024-08-01T05:15:12.135390Z","iopub.status.idle":"2024-08-01T05:19:04.424700Z","shell.execute_reply.started":"2024-08-01T05:15:12.135360Z","shell.execute_reply":"2024-08-01T05:19:04.423328Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# график изменения функций потерь для train и test\nplt.figure(figsize=(10, 6))\nplt.plot(range(1, len(loss_train_arr) + 1), loss_train_arr, label=\"train loss\")\nplt.plot(range(1, len(loss_train_arr) + 1), loss_val_arr, label=\"validation loss\")\nplt.title(\"Loss curves\")\nplt.legend(loc='upper right')\nplt.xlabel(\"Epoch\")\nplt.ylabel(\"Value\")","metadata":{"execution":{"iopub.status.busy":"2024-08-01T05:25:35.338379Z","iopub.execute_input":"2024-08-01T05:25:35.338754Z","iopub.status.idle":"2024-08-01T05:25:35.606629Z","shell.execute_reply.started":"2024-08-01T05:25:35.338724Z","shell.execute_reply":"2024-08-01T05:25:35.605661Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Тестирование","metadata":{}},{"cell_type":"code","source":"# инстанс кастомного датасета для val\nval_audio_dataset = CustomAudioDataset(val[\"path\"].tolist(), val[\"label\"].tolist(), target_rate, target_length)\nval_dataloader = DataLoader(val_audio_dataset, batch_size=batch_size, shuffle=False)","metadata":{"execution":{"iopub.status.busy":"2024-08-01T05:25:45.317937Z","iopub.execute_input":"2024-08-01T05:25:45.318812Z","iopub.status.idle":"2024-08-01T05:25:45.324086Z","shell.execute_reply.started":"2024-08-01T05:25:45.318775Z","shell.execute_reply":"2024-08-01T05:25:45.323120Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"custom_model.eval()\nall_y_true = []\nall_y_pred = []\npbar = tqdm(val_dataloader, ascii=True, desc=\"Validation\")\nwith torch.no_grad():\n    for i, (X, y) in enumerate(pbar):\n        X, y = X.to(device), y.to(device)\n        pred = custom_model(X)   \n        _, predicted_labels = torch.max(pred, 1)\n        all_y_true = all_y_true + y.tolist()\n        all_y_pred = all_y_pred + predicted_labels.tolist()\ntarget_names = [\"Negative\", \"Dog\", \"Wolf\"]     \nprint(classification_report(all_y_true, all_y_pred, target_names=target_names))","metadata":{"execution":{"iopub.status.busy":"2024-08-01T05:25:59.195285Z","iopub.execute_input":"2024-08-01T05:25:59.196155Z","iopub.status.idle":"2024-08-01T05:27:20.157695Z","shell.execute_reply.started":"2024-08-01T05:25:59.196122Z","shell.execute_reply":"2024-08-01T05:27:20.156428Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# построение матрицы ошибок\ncm = confusion_matrix(all_y_true, all_y_pred)","metadata":{"execution":{"iopub.status.busy":"2024-08-01T05:27:24.031888Z","iopub.execute_input":"2024-08-01T05:27:24.032238Z","iopub.status.idle":"2024-08-01T05:27:24.039339Z","shell.execute_reply.started":"2024-08-01T05:27:24.032211Z","shell.execute_reply":"2024-08-01T05:27:24.038361Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# изображение матрицы ошибок\nplt.figure(figsize=(10, 7))\nsns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=['Predicted negative', 'Predicted dog', 'Predicted wolf'], yticklabels=['Actual negative', 'Actual dog', 'Actual wolf'])\nplt.xlabel('Predicted')\nplt.ylabel('Actual')\nplt.title('Confusion Matrix')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-08-01T05:28:15.438403Z","iopub.execute_input":"2024-08-01T05:28:15.438773Z","iopub.status.idle":"2024-08-01T05:28:15.698080Z","shell.execute_reply.started":"2024-08-01T05:28:15.438742Z","shell.execute_reply":"2024-08-01T05:28:15.697173Z"},"trusted":true},"execution_count":null,"outputs":[]}]}